Title: About 

## The Blog

With the explosion of Data Science (a term that went through many evolutions), we are seeing a field that was the pure domain of the statisticians being reshaped with the wide spread knowledge of Machine Learning. But as the crochety statisticians have been overwhelmed, there has been a corresponding loss in the skepticism they brought to the table. Thinking about the hype we see about Deep Learning, can you recall a technique in stats that ever received as much hype? Statistics would always report prediction/credible intervals to tell you how good they were, and pessimism in one's results was the de facto standard. Nowadays, training a model of some topology and getting results seems to come with "We Did It" banner and I think the loss of doubt in the field has been a net loss for all practitioners.

This blog aims at looking at bringing pessimism back to statistics and ML and looks at not just results, but hidden costs to using the fanciest model on the market. Maintenance of models, deployment and interpretability for someone not technically versed are big issues that nobody ever discusses in this industry and are things that should be considered when approaching problems. Recently, the slew of data makes it very easy to generate biased models that reflect the bias of the underlying humans/data and this is an area Data Scientist and ML Engineers are not taking seriously yet.

This is github after all, so this will be mostly technically focussed. 


## Me

I'm Varun, I was a Data Scientist before the term existed. My first job title was DSP research, I then called my work Data Mining for a while, graduated to R&D Engineer and then Analyst before the term Data Scientist arrived on scene. I studied Signal Processing and Statistics at UNSW, and have worked in the Sydney startup scene, Cochlear and most recently at Hudson River Trading in Singapore.

I'm a Bayesian statistician, so I love impractical solutions :P, and always fail to find modern day uses. Bayesian statistics has not found a huge amount of traction in today's ML landscape, the GPU does not provide a fundamental speedup to MCMC algorithms and the additional compute power could be better directed at ensemble models or many different approaches. There are niche applications, especially in Biomathematics where the data is poor and limited and parameter spaces are large, but very limited outside academia. However, it informs my thinking and the way I approach problems.

I love programming in Python and I'm very familiar with the scientific stack. I remember hunting for pre-compiled binaries of numpy for windows in 2012, and have even contributed to numpy, [adding automatic bin estimation for histograms](https://github.com/numpy/numpy/pull/6029) plus a bunch of bugfixes since it's merge. I have dabbled in CUDA, [presenting my work on it](https://github.com/nayyarv/PyCudaIntro) with GMMs, and have hacked the CPython source code regarding binary operations for no reason whatsoever and [have a presentation on it too](https://github.com/nayyarv/CpythonLookingGlass). I do a lot of one off scripts in R, the tidyverse makes data cleaning really easy (and ggplot is the best thing ever), but I find writing larger programs is a horrid experience. I'm a better programmer than most, but I'm not a proper software engineer.

(Yes the above doubles as a "Hire Me" spiel)