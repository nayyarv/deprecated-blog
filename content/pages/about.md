Title: About 

## The Blog

With the explosion of Data Science (a term that went through many evolutions), we are seeing a field that was the pure domain of the statisticians being reshaped with the wide spread knowledge of Machine Learning. But as the crochety statisticians have been overwhelmed, there has been a corresponding loss in the skepticism they brought to the table. Thinking about the hype we see about Deep Learning, can you recall a technique in stats that ever received as much hype (Maybe the bootstrap)? Statistics would always report prediction/credible intervals to tell you how good they were, and pessimism in one's results was the de facto standard. Nowadays, training a model of some topology and getting results seems to come with "We Did It" banner and I think the loss of doubt in the field has been a net loss for all practitioners.

This blog aims at looking at bringing pessimism back to statistics and ML and looks at not just results, but hidden costs to using the fanciest model on the market. Maintenance of models, deployment and interpretability for someone not technically versed are big issues that nobody ever discusses in this industry and are things that should be considered when approaching problems. Recently, the slew of data makes it very easy to generate biased models that reflect the bias of the underlying humans/data and this is an area Data Scientist and ML Engineers are not taking seriously yet.

Additionally, I'd like to do articles on Bayesian Inference. Bayesian statistics has not found a huge amount of traction in today's ML landscape, the GPU does not provide a fundamental speedup to MCMC algorithms and the additional compute power could be better directed at ensemble models or many different approaches. There have been niche uses, but I believe the ML of tomorrow is inference on smaller datasets and I think Bayesian Inference is uniquely suited to these problems. Already we're seeing issues where intialisation methods are discussed, where training needs to be run a few times to find the best fit and these are all symptoms of deeper problems that Bayesian approaches can solve. Additionally, a Bayesian approach makes one much more able to reason about models and data and that's a very valuable thing to have.


## Me

I'm Varun, I was a Data Scientist before the term existed. My first job title was DSP researcher, I then called my work Data Mining for a while, graduated to R&D Engineer and then Analyst before the term Data Scientist arrived on scene. 
I studied Signal Processing and Statistics at UNSW, and have worked in the Sydney startup scene, Cochlear, Hudson River Trading in Singapore, the Australian Greens and of late, Dolby.

I love programming in Python and I'm very familiar with the scientific stack. I remember hunting for pre-compiled binaries of numpy for windows in 2012, and have even contributed to numpy, [adding automatic bin estimation for histograms](https://github.com/numpy/numpy/pull/6029) plus a bunch of bugfixes since it's merge. I have developed in CUDA, [presenting my work on it](https://github.com/nayyarv/PyCudaIntro) with GMMs, and have hacked the CPython source code regarding binary operations for no reason whatsoever and [have a presentation on it too](https://github.com/nayyarv/CpythonLookingGlass). I do a lot of one off scripts in R, the tidyverse makes data cleaning really easy (and dplyr is the best thing ever), but I find writing larger programs less than excellent, which I document in a talk on [it's inteRnals](https://github.com/nayyarv/inteRnals). 

Most of my Data Science work has always been stored in company repos and confidential, I never did much Kaggle after getting a job, so my blog is a bit sparse, but I hope to fix that here and there.